---
layout: post
title:  "OLiVia-Nav: An Online Lifelong Vision Language Approach for Mobile Robot Social Navigation"
date:   2024-08-09 22:21:59 +00:00
# image: /images/olivia_nav.png
video: /images/olivia-nav.mp4
categories: research
author: "Daniel Choi"
authors: "Siddarth Narasimhan, Aaron Hao Tan, <strong>Daniel Choi</strong>, Goldie Nejat"
venue: "International Conference on Robotics and Automation 2025, (Pending)"
venue2: "<a href=https://sites.google.com/view/langrob-corl24/>LangRob @ CoRL 2024</a>: Workshop on Language and Robot Learning"
venue3: "<a href=https://llhomerobots.github.io/>LLHomeRobots @ CoRL 2024: Workshop on Lifelong Learning for Home Robots</a> <strong>(Spotlight)</strong>"
arxiv: https://www.arxiv.org/abs/2409.13675
youtube: https://www.youtube.com/watch?v=eyFJiOIITO0
paper: "/pdfs/OLiVia_Nav_Paper_Final.pdf"
website: "link"
---
We introduce OLiVia-Nav, an online lifelong vision language architecture for mobile robot social navigation. By leveraging large vision-language models (VLMs) and a novel distillation process called SC-CLIP, OLiVia-Nav efficiently encodes social and environmental contexts, adapting to dynamic human environments. 