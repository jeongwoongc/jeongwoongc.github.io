---
layout: post
title:  "Find Everything: A General Vision Language Model Approach to Multi-Object Search"
date:   2024-09-21 22:21:59 +00:00
image:
video: /images/finder.mp4
categories: research
author: "Daniel Choi"
authors: "<strong>Daniel Choi</strong>, Angus Fung, Haitong Wang, Aaron Hao Tan"
venue: "International Conference on Robotics and Automation 2025, (Pending) 
        LangRob @ CoRL 2024: Workshop on Language and Robot Learning"
arxiv: https://arxiv.org/abs/2410.00388
paper: /pdfs/Finder_Final.pdf
website: https://find-all-my-things.github.io/
---
We present Finder, a novel approach to the multi-object search problem that leverages vision language models (VLMs) to efficiently locate multiple objects in diverse unknown environments. Our method combines semantic mapping with spatio-probabilistic reasoning and adaptive planning, improving object recognition and scene understanding through VLMs.